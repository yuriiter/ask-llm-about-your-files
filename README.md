# ğŸš€ Semantic Search Platform

A powerful full-stack platform combining intelligent vector search capabilities with a modern web interface. This platform enables semantic search across multiple file types using state-of-the-art ML models, wrapped in a user-friendly interface with modularity and scalability.

## ğŸŒŸ System Overview

The platform consists of two main microservices:

### Vector Search Service (Python)

- Advanced semantic search engine
- Multi-modal search capabilities (text & images)
- Multiple file format processing (ZIP, RAR archives, PDF documents, TXT files and images)
- High-performance vector database (Milvus)
- Neural processing with CLIP & Sentence Transformers

### Web Application (Next.js)

- Secure authentication and authorization with OAuth
- LLM integration
- High-performance gRPC communication
- Database management
- Modern UI with Ant Design

## âœ¨ Key Features

- **Intelligent Search**

  - ğŸ” Semantic search across documents and images
  - ğŸ“„ Support for multiple file formats (PDF, TXT, Images, Archives)
  - ğŸ¤– State-of-the-art ML models for understanding content
  - âš¡ High-performance vector similarity search

- **Modern Web Interface**
  - ğŸ¨ Intuitive, responsive design
  - ğŸ” Secure OAuth authentication
  - ğŸ”„ Context-based LLM itnegration

## ğŸ—ï¸ Architecture

The platform follows a microservices architecture with clean separation of concerns:

### System Components

1. **Frontend (Next.js)**

   - App Router for routing
   - Ant Design components
   - Server-side rendering
   - SEO optimization

2. **Backend API (Next.js)**

   - API routes
   - MySQL with Prisma ORM

3. **Vector Search Service (Python)**

   - File processing pipeline
   - Embedding generation
   - Vector storage and retrieval
   - gRPC/REST APIs

4. **Databases**
   - MySQL for application data
   - Milvus for vector storage

### Communication Flow

1. User signs in â†’ Web App
2. User uploads files â†’ Web App
3. Web App processes request â†’ Vector Service
4. Vector Service generates embeddings â†’ Milvus
5. Search queries flow through similar pipeline
6. Results aggregated, constructed into context prompt for LLM
7. User gets relevant response regarding their documents

---

Built with â¤ï¸ using Next.js, Python, and cutting-edge ML models
